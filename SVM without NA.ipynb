{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6aeab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from scipy.stats import mstats\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Final dataset for real3.xlsx', index_col = 0)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec100bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2031996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Country ISO code'] = data['Country ISO code'].astype('category')\n",
    "data['Size'] = data['Size'].astype('category')\n",
    "data['Accounting practice'] = data['Accounting practice'].astype('category')\n",
    "data['NACE Rev. 2'] = data['NACE Rev. 2'].astype('category')\n",
    "\n",
    "X = data[[\"Country ISO code\",\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\",\"Hubs\"]]\n",
    "y = data[\"ETR\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con = X_train[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_cat = X_train[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_con)\n",
    "StandardScaler()\n",
    "X_train_con = scaler.transform(X_train_con)\n",
    "\n",
    "iim=IterativeImputer(#estimator=xgb.XGBRegressor(),\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con = pd.DataFrame(iim.fit_transform(X_train_con), index = X_train.index)\n",
    "imputed_X_train_con.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "\n",
    "imputed_X_train_cat = pd.get_dummies(X_train_cat)\n",
    "imputed_X_train = pd.concat([imputed_X_train_con, imputed_X_train_cat], axis = 1)\n",
    "\n",
    "drop_na = pd.concat([imputed_X_train, y_train], axis = 1)\n",
    "drop_na = drop_na.dropna()\n",
    "drop_na = pd.DataFrame(drop_na)\n",
    "\n",
    "X_train_final = drop_na.loc[:,:'Accounting practice_US GAAP']\n",
    "y_train_final = drop_na['ETR']\n",
    "\n",
    "X_test_con = X_test[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_cat = X_test[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con = scaler.transform(X_test_con)\n",
    "\n",
    "imputed_X_test_con = pd.DataFrame(iim.transform(X_test_con), index = X_test.index)\n",
    "imputed_X_test_con.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "\n",
    "imputed_X_test_cat = pd.get_dummies(X_test_cat)\n",
    "imputed_X_test = pd.concat([imputed_X_test_con, imputed_X_test_cat], axis = 1)\n",
    "\n",
    "drop_na = pd.concat([imputed_X_test, y_test], axis = 1)\n",
    "#drop_na = drop_na.dropna()\n",
    "drop_na = pd.DataFrame(drop_na)\n",
    "\n",
    "X_test_final = drop_na.loc[:,:'Accounting practice_US GAAP']\n",
    "y_test_final = drop_na['ETR']\n",
    "\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)\n",
    "print('Imputed' , X_train_final.shape, y_train_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(dataframe, upper, lower, column_to_winsor):\n",
    "    dataframe = dataframe.sort_values(column_to_winsor, ascending=False, ignore_index = True)\n",
    "    amount = dataframe[column_to_winsor].count()\n",
    "    up = int(amount * (upper/100))\n",
    "    low = int(amount * (lower/100))\n",
    "    data_winsor = dataframe.loc[low:up]\n",
    "    return data_winsor\n",
    "\n",
    "data_winsor = winsorize(data, 99,  1, 'ETR') \n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Operating revenue\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Total assets\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Current liabilities\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Betweenness\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Long term debt\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"PBT\")\n",
    "\n",
    "X_winsor = data_winsor[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\",\"Hubs\"]]\n",
    "y_winsor = data_winsor[\"ETR\"]\n",
    "\n",
    "X_train_winsor, X_test_winsor, y_train_winsor, y_test_winsor = train_test_split(X_winsor, y_winsor, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con_winsor = X_train_winsor[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_cat_winsor = X_train_winsor[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_con_winsor)\n",
    "StandardScaler()\n",
    "X_train_con_winsor = scaler.transform(X_train_con_winsor)\n",
    "\n",
    "iim=IterativeImputer(#estimator=xgb.XGBRegressor(),\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "#skip_complete=True,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con_winsor = pd.DataFrame(iim.fit_transform(X_train_con_winsor), index = X_train_winsor.index)\n",
    "imputed_X_train_con_winsor.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "\n",
    "#imputed_X_train = imputed_X_train.dropna()\n",
    "imputed_X_train_cat_winsor = pd.get_dummies(X_train_cat_winsor)\n",
    "imputed_X_train_winsor = pd.concat([imputed_X_train_con_winsor, imputed_X_train_cat_winsor], axis = 1)\n",
    "\n",
    "drop_na_winsor = pd.concat([imputed_X_train_winsor, y_train_winsor], axis = 1)\n",
    "drop_na_winsor = drop_na_winsor.dropna()\n",
    "drop_na_winsor = pd.DataFrame(drop_na_winsor)\n",
    "\n",
    "X_train_final_winsor = drop_na_winsor.loc[:,:'Accounting practice_US GAAP']\n",
    "y_train_final_winsor = drop_na_winsor['ETR']\n",
    "\n",
    "X_test_con_winsor = X_test_winsor[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_cat_winsor = X_test_winsor[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con_winsor = scaler.transform(X_test_con_winsor)\n",
    "\n",
    "imputed_X_test_con_winsor = pd.DataFrame(iim.transform(X_test_con_winsor), index = X_test_winsor.index)\n",
    "imputed_X_test_con_winsor.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "\n",
    "imputed_X_test_cat_winsor = pd.get_dummies(X_test_cat_winsor)\n",
    "imputed_X_test_winsor = pd.concat([imputed_X_test_con_winsor, imputed_X_test_cat_winsor], axis = 1)\n",
    "\n",
    "drop_na_winsor = pd.concat([imputed_X_test_winsor, y_test_winsor], axis = 1)\n",
    "#drop_na = drop_na.dropna()\n",
    "drop_na_winsor = pd.DataFrame(drop_na_winsor)\n",
    "\n",
    "X_test_final_winsor = drop_na_winsor.loc[:,:'Accounting practice_US GAAP']\n",
    "y_test_final_winsor = drop_na_winsor['ETR']\n",
    "\n",
    "print('Train', X_train_winsor.shape, y_train_winsor.shape)\n",
    "print('Test', X_test_winsor.shape, y_test_winsor.shape)\n",
    "print('Imputed train' , X_train_final_winsor.shape, y_train_final_winsor.shape)\n",
    "print('Imputed test' , X_test_final_winsor.shape, y_test_final_winsor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(dataframe, upper, lower, column_to_winsor):\n",
    "    dataframe = dataframe.sort_values(column_to_winsor, ascending=False, ignore_index = True)\n",
    "    amount = dataframe[column_to_winsor].count()\n",
    "    up = int(amount * (upper/100))\n",
    "    low = int(amount * (lower/100))\n",
    "    data_winsor = dataframe.loc[low:up]\n",
    "    return data_winsor\n",
    "\n",
    "data_winsor2 = winsorize(data, 97.5,  4, 'ETR') \n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Operating revenue\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Total assets\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Current liabilities\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Betweenness\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Long term debt\")\n",
    "data_winsor2 = winsorize(data_winsor2, 97.5,  2.5, \"PBT\")\n",
    "\n",
    "X_winsor2 = data_winsor2[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\",\"Hubs\"]]\n",
    "y_winsor2 = data_winsor2[\"ETR\"]\n",
    "\n",
    "X_train_winsor2, X_test_winsor2, y_train_winsor2, y_test_winsor2 = train_test_split(X_winsor2, y_winsor2, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con_winsor2 = X_train_winsor2[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_cat_winsor2 = X_train_winsor2[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_con_winsor2)\n",
    "StandardScaler()\n",
    "X_train_con_winsor2 = scaler.transform(X_train_con_winsor2)\n",
    "\n",
    "iim=IterativeImputer(#estimator=xgb.XGBRegressor(),\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "#skip_complete=True,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con_winsor2 = pd.DataFrame(iim.fit_transform(X_train_con_winsor2), index = X_train_winsor2.index)\n",
    "imputed_X_train_con_winsor2.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "\n",
    "#imputed_X_train = imputed_X_train.dropna()\n",
    "imputed_X_train_cat_winsor2 = pd.get_dummies(X_train_cat_winsor2)\n",
    "imputed_X_train_winsor2 = pd.concat([imputed_X_train_con_winsor2, imputed_X_train_cat_winsor2], axis = 1)\n",
    "\n",
    "drop_na_winsor2 = pd.concat([imputed_X_train_winsor2, y_train_winsor2], axis = 1)\n",
    "drop_na_winsor2 = drop_na_winsor2.dropna()\n",
    "drop_na_winsor2 = pd.DataFrame(drop_na_winsor2)\n",
    "\n",
    "X_train_final_winsor2 = drop_na_winsor2.loc[:,:'Accounting practice_US GAAP']\n",
    "y_train_final_winsor2 = drop_na_winsor2['ETR']\n",
    "\n",
    "X_test_con_winsor2 = X_test_winsor2[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_cat_winsor2 = X_test_winsor2[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con_winsor2 = scaler.transform(X_test_con_winsor2)\n",
    "\n",
    "imputed_X_test_con_winsor2 = pd.DataFrame(iim.transform(X_test_con_winsor2), index = X_test_winsor2.index)\n",
    "imputed_X_test_con_winsor2.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "\n",
    "imputed_X_test_cat_winsor2 = pd.get_dummies(X_test_cat_winsor2)\n",
    "imputed_X_test_winsor2 = pd.concat([imputed_X_test_con_winsor2, imputed_X_test_cat_winsor2], axis = 1)\n",
    "\n",
    "drop_na_winsor2 = pd.concat([imputed_X_test_winsor2, y_test_winsor2], axis = 1)\n",
    "#drop_na = drop_na.dropna()\n",
    "drop_na_winsor2 = pd.DataFrame(drop_na_winsor2)\n",
    "\n",
    "X_test_final_winsor2 = drop_na_winsor2.loc[:,:'Accounting practice_US GAAP']\n",
    "y_test_final_winsor2 = drop_na_winsor2['ETR']\n",
    "\n",
    "print('Train', X_train_winsor2.shape, y_train_winsor2.shape)\n",
    "print('Test', X_test_winsor2.shape, y_test_winsor2.shape)\n",
    "print('Imputed train' , X_train_final_winsor2.shape, y_train_final_winsor2.shape)\n",
    "print('Imputed test' , X_test_final_winsor2.shape, y_test_final_winsor2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c25339",
   "metadata": {},
   "outputs": [],
   "source": [
    ".isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "kernel = ['rbf']\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma,\n",
    "               'kernel': kernel}\n",
    "\n",
    "svr = SVR()\n",
    "svr_random = GridSearchCV(estimator = svr, param_grid = random_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random.fit(X_train_final, y_train_final)\n",
    "best_parameters = svr_random.best_estimator_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79760ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [150, 200, 250]\n",
    "gamma = [0.04]\n",
    "kernel = ['rbf']\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma,\n",
    "               'kernel': kernel}\n",
    "\n",
    "svr_winsor = SVR()\n",
    "svr_random_winsor = GridSearchCV(estimator = svr_winsor, param_grid = random_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random_winsor.fit(X_train_final_winsor, y_train_final_winsor)\n",
    "best_parameters_winsor = svr_random_winsor.best_estimator_\n",
    "print(best_parameters_winsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e271125",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svr_winsor2 = SVR()\n",
    "svr_random_winsor2 = RandomizedSearchCV(estimator = svr_winsor2, param_grid = random_grid, n_iter = 10, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random_winsor2.fit(X_train_final_winsor2, y_train_final_winsor2)\n",
    "best_parameters_winsor2 = svr_random_winsor2.best_estimator_\n",
    "print(best_parameters_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [700, 1000, 1300]\n",
    "gamma = [0.04, 0.01, 0.005]\n",
    "kernel = ['rbf']\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma,\n",
    "               'kernel': kernel}\n",
    "\n",
    "svr_winsor2 = SVR()\n",
    "svr_random_winsor2 = GridSearchCV(estimator = svr_winsor2, param_grid = random_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random_winsor2.fit(X_train_final_winsor2, y_train_final_winsor2)\n",
    "best_parameters_winsor2 = svr_random_winsor2.best_estimator_\n",
    "print(best_parameters_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b92a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_for_pred = SVR(C=1000, gamma=0.1)\n",
    "\n",
    "svr_for_pred.fit(X_train_final,y_train_final)\n",
    "\n",
    "y_pred = svr_for_pred.predict(X_test_final)\n",
    "\n",
    "mae = mean_absolute_error(y_test_final, y_pred)\n",
    "mse = mean_squared_error(y_test_final, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "d_nonan = {'With outliers': [mse, rmse, mae]}\n",
    "df_nonan = pd.DataFrame(d_nonan, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420be8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred_winsor = SVR(C=250, gamma=0.04)\n",
    "\n",
    "rf_for_pred_winsor.fit(X_train_final_winsor,y_train_final_winsor)\n",
    "\n",
    "y_pred_winsor = rf_for_pred_winsor.predict(X_test_final_winsor)\n",
    "\n",
    "mae_winsor = mean_absolute_error(y_test_final_winsor, y_pred_winsor)\n",
    "mse_winsor = mean_squared_error(y_test_final_winsor, y_pred_winsor)\n",
    "rmse_winsor = np.sqrt(mse_winsor)\n",
    "d_nonan_winsor = {'1% outliers removed': [mse_winsor, rmse_winsor, mae_winsor]}\n",
    "df_nonan_winsor = pd.DataFrame(d_nonan_winsor, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan_winsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be13038",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred_winsor2 = SVR(C=150, gamma=0.04)\n",
    "\n",
    "rf_for_pred_winsor2.fit(X_train_final_winsor2,y_train_final_winsor2)\n",
    "\n",
    "y_pred_winsor2 = rf_for_pred_winsor2.predict(X_test_final_winsor2)\n",
    "\n",
    "mae_winsor2 = mean_absolute_error(y_test_final_winsor2, y_pred_winsor2)\n",
    "mse_winsor2 = mean_squared_error(y_test_final_winsor2, y_pred_winsor2)\n",
    "rmse_winsor2 = np.sqrt(mse_winsor2)\n",
    "d_nonan_winsor2 = {'5% outliers removed': [mse_winsor2, rmse_winsor2, mae_winsor2]}\n",
    "df_nonan_winsor2 = pd.DataFrame(d_nonan_winsor2, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_LR = pd.concat([df_nonan, df_nonan_winsor, df_nonan_winsor2], axis = 1)\n",
    "print(results_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddea5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_LR.to_excel(\"results_SVM.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4975632",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_error = pd.DataFrame(data = [(y_pred_winsor2-y_test_final_winsor2)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_error = pd.concat([X_test_final_winsor2, y_error], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a06996",
   "metadata": {},
   "outputs": [],
   "source": [
    "cormat = y_error.corr()\n",
    "round(cormat,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ced0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETR_heatmap = cormat['ETR']\n",
    "ETR_heatmap = pd.DataFrame(ETR_heatmap)\n",
    "ETR_heatmap.rename(columns = {'ETR':'ETR error'}, inplace = True)\n",
    "ETR_heatmap = ETR_heatmap.drop('ETR')\n",
    "ETR_heatmap.sort_values('ETR error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(4, 10), dpi=200)\n",
    "sns.heatmap(ETR_heatmap.sort_values('ETR error'), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4000d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "y_error = pd.DataFrame(data = [(y_pred_winsor2-y_test_final_winsor2)]).T\n",
    "X_test_final_winsor2_subset = X_test_final_winsor2[['Debtors', 'Accounting practice_US GAAP', 'PBT', 'Accounting practice_Local GAAP', 'Accounting practice_IFRS - not fully compliant']]\n",
    "y_error = pd.concat([X_test_final_winsor2_subset, y_error], axis = 1)\n",
    "\n",
    "cormat = y_error.corr()\n",
    "round(cormat,3)\n",
    "\n",
    "ETR_heatmap = cormat['ETR']\n",
    "ETR_heatmap = pd.DataFrame(ETR_heatmap)\n",
    "ETR_heatmap.rename(columns = {'ETR':'ETR error'}, inplace = True)\n",
    "ETR_heatmap = ETR_heatmap.drop('ETR')\n",
    "\n",
    "figure(figsize=(2, 3), dpi=200)\n",
    "sns.heatmap(ETR_heatmap.sort_values('ETR error'), annot = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
