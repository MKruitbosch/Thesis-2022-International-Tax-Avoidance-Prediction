{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from scipy.stats import mstats\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728aa6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Final dataset for real3.xlsx', index_col = 0)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2375509",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7142d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Country ISO code'] = data['Country ISO code'].astype('category')\n",
    "data['Size'] = data['Size'].astype('category')\n",
    "data['Accounting practice'] = data['Accounting practice'].astype('category')\n",
    "data['NACE Rev. 2'] = data['NACE Rev. 2'].astype('category')\n",
    "\n",
    "X = data[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\"]]\n",
    "y = data[\"ETR\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con = X_train[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_na = X_train[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_train_cat = X_train[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler_con = StandardScaler()\n",
    "scaler_con.fit(X_train_con)\n",
    "scaler_na = StandardScaler()\n",
    "scaler_na.fit(X_train_na)\n",
    "StandardScaler()\n",
    "X_train_con = scaler_con.transform(X_train_con)\n",
    "\n",
    "X_train_na = pd.DataFrame(scaler_na.transform(X_train_na), index = X_train.index)\n",
    "X_train_na.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "iim=IterativeImputer(\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con = pd.DataFrame(iim.fit_transform(X_train_con), index = X_train.index)\n",
    "imputed_X_train_con.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_train_cat = pd.get_dummies(X_train_cat)\n",
    "\n",
    "drop_na = pd.concat([imputed_X_train_con, imputed_X_train_cat, X_train_na, y_train], axis = 1)\n",
    "drop_na = drop_na.dropna()\n",
    "drop_na = pd.DataFrame(drop_na)\n",
    "\n",
    "X_train_final = drop_na.loc[:,:\"Eigenvector\"]\n",
    "y_train_final = drop_na['ETR']\n",
    "\n",
    "X_test_con = X_test[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_na = X_test[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_test_cat = X_test[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con = scaler_con.transform(X_test_con)\n",
    "\n",
    "X_test_na = pd.DataFrame(scaler_na.transform(X_test_na), index = X_test.index)\n",
    "X_test_na.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "imputed_X_test_con = pd.DataFrame(iim.transform(X_test_con), index = X_test.index)\n",
    "imputed_X_test_con.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_test_cat = pd.get_dummies(X_test_cat)\n",
    "\n",
    "drop_na = pd.concat([imputed_X_test_con, imputed_X_test_cat, X_test_na, y_test], axis = 1)\n",
    "drop_na = drop_na.dropna()\n",
    "drop_na = pd.DataFrame(drop_na)\n",
    "\n",
    "X_test_final = drop_na.loc[:,:\"Eigenvector\"]\n",
    "y_test_final = drop_na['ETR']\n",
    "\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)\n",
    "print('Imputed' , X_train_final.shape, y_train_final.shape)\n",
    "print('Imputed_test' , X_test_final.shape, y_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a871e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(dataframe, upper, lower, column_to_winsor):\n",
    "    dataframe = dataframe.sort_values(column_to_winsor, ascending=False, ignore_index = True)\n",
    "    amount = dataframe[column_to_winsor].count()\n",
    "    up = int(amount * (upper/100))\n",
    "    low = int(amount * (lower/100))\n",
    "    data_winsor = dataframe.loc[low:up]\n",
    "    return data_winsor\n",
    "\n",
    "data_winsor = winsorize(data, 99,  1, 'ETR') \n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Operating revenue\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Total assets\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Current liabilities\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Betweenness\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Long term debt\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"PBT\")\n",
    "\n",
    "X_winsor = data_winsor[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\"]]\n",
    "y_winsor = data_winsor[\"ETR\"]\n",
    "\n",
    "X_train_winsor, X_test_winsor, y_train_winsor, y_test_winsor = train_test_split(X_winsor, y_winsor, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con_winsor = X_train_winsor[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_na_winsor = X_train_winsor[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_train_cat_winsor = X_train_winsor[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler_con_winsor = StandardScaler()\n",
    "scaler_con_winsor.fit(X_train_con_winsor)\n",
    "scaler_na_winsor = StandardScaler()\n",
    "scaler_na_winsor.fit(X_train_na_winsor)\n",
    "StandardScaler()\n",
    "X_train_con_winsor = scaler_con_winsor.transform(X_train_con_winsor)\n",
    "\n",
    "X_train_na_winsor = pd.DataFrame(scaler_na_winsor.transform(X_train_na_winsor), index = X_train_winsor.index)\n",
    "X_train_na_winsor.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "iim=IterativeImputer(\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con_winsor = pd.DataFrame(iim.fit_transform(X_train_con_winsor), index = X_train_winsor.index)\n",
    "imputed_X_train_con_winsor.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_train_cat_winsor = pd.get_dummies(X_train_cat_winsor)\n",
    "\n",
    "drop_na_winsor = pd.concat([imputed_X_train_con_winsor, imputed_X_train_cat_winsor, X_train_na_winsor, y_train_winsor], axis = 1)\n",
    "drop_na_winsor = drop_na_winsor.dropna()\n",
    "drop_na_winsor = pd.DataFrame(drop_na_winsor)\n",
    "\n",
    "X_train_final_winsor = drop_na_winsor.loc[:,:'Eigenvector']\n",
    "y_train_final_winsor = drop_na_winsor['ETR']\n",
    "\n",
    "X_test_con_winsor = X_test_winsor[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_na_winsor = X_test_winsor[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_test_cat_winsor = X_test_winsor[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con_winsor = scaler_con_winsor.transform(X_test_con_winsor)\n",
    "\n",
    "X_test_na_winsor = pd.DataFrame(scaler_na_winsor.transform(X_test_na_winsor), index = X_test_winsor.index)\n",
    "X_test_na_winsor.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "imputed_X_test_con_winsor = pd.DataFrame(iim.transform(X_test_con_winsor), index = X_test_winsor.index)\n",
    "imputed_X_test_con_winsor.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_test_cat_winsor = pd.get_dummies(X_test_cat_winsor)\n",
    "\n",
    "drop_na_winsor = pd.concat([imputed_X_test_con_winsor, imputed_X_test_cat_winsor, X_test_na_winsor, y_test_winsor], axis = 1)\n",
    "drop_na_winsor = pd.DataFrame(drop_na_winsor)\n",
    "\n",
    "X_test_final_winsor = drop_na_winsor.loc[:,:'Eigenvector']\n",
    "y_test_final_winsor = drop_na_winsor['ETR']\n",
    "\n",
    "print('Train', X_train_winsor.shape, y_train_winsor.shape)\n",
    "print('Test', X_test_winsor.shape, y_test_winsor.shape)\n",
    "print('Imputed' , X_train_final_winsor.shape, y_train_final_winsor.shape)\n",
    "print('Imputed' , X_test_final_winsor.shape, y_test_final_winsor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(dataframe, upper, lower, column_to_winsor):\n",
    "    dataframe = dataframe.sort_values(column_to_winsor, ascending=False, ignore_index = True)\n",
    "    amount = dataframe[column_to_winsor].count()\n",
    "    up = int(amount * (upper/100))\n",
    "    low = int(amount * (lower/100))\n",
    "    data_winsor = dataframe.loc[low:up]\n",
    "    return data_winsor\n",
    "\n",
    "data_winsor2 = winsorize(data, 97.5,  4, 'ETR') \n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Operating revenue\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Total assets\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Current liabilities\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Betweenness\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Long term debt\")\n",
    "data_winsor2 = winsorize(data_winsor2, 97.5,  2.5, \"PBT\")\n",
    "\n",
    "X_winsor2 = data_winsor2[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\"]]\n",
    "y_winsor2 = data_winsor2[\"ETR\"]\n",
    "\n",
    "X_train_winsor2, X_test_winsor2, y_train_winsor2, y_test_winsor2 = train_test_split(X_winsor2, y_winsor2, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con_winsor2 = X_train_winsor2[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_na_winsor2 = X_train_winsor2[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_train_cat_winsor2 = X_train_winsor2[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler_con_winsor2 = StandardScaler()\n",
    "scaler_con_winsor2.fit(X_train_con_winsor2)\n",
    "scaler_na_winsor2 = StandardScaler()\n",
    "scaler_na_winsor2.fit(X_train_na_winsor2)\n",
    "StandardScaler()\n",
    "X_train_con_winsor2 = scaler_con_winsor2.transform(X_train_con_winsor2)\n",
    "\n",
    "X_train_na_winsor2 = pd.DataFrame(scaler_na_winsor2.transform(X_train_na_winsor2), index = X_train_winsor2.index)\n",
    "X_train_na_winsor2.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "iim=IterativeImputer(\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con_winsor2 = pd.DataFrame(iim.fit_transform(X_train_con_winsor2), index = X_train_winsor2.index)\n",
    "imputed_X_train_con_winsor2.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_train_cat_winsor2 = pd.get_dummies(X_train_cat_winsor2)\n",
    "\n",
    "drop_na_winsor2 = pd.concat([imputed_X_train_con_winsor2, imputed_X_train_cat_winsor2, X_train_na_winsor2, y_train_winsor2], axis = 1)\n",
    "drop_na_winsor2 = drop_na_winsor2.dropna()\n",
    "drop_na_winsor2 = pd.DataFrame(drop_na_winsor2)\n",
    "\n",
    "X_train_final_winsor2 = drop_na_winsor2.loc[:,:'Eigenvector']\n",
    "y_train_final_winsor2 = drop_na_winsor2['ETR']\n",
    "\n",
    "X_test_con_winsor2 = X_test_winsor2[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_na_winsor2 = X_test_winsor2[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_test_cat_winsor2 = X_test_winsor2[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con_winsor2 = scaler_con_winsor2.transform(X_test_con_winsor2)\n",
    "\n",
    "X_test_na_winsor2 = pd.DataFrame(scaler_na_winsor2.transform(X_test_na_winsor2), index = X_test_winsor2.index)\n",
    "X_test_na_winsor2.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "imputed_X_test_con_winsor2 = pd.DataFrame(iim.transform(X_test_con_winsor2), index = X_test_winsor2.index)\n",
    "imputed_X_test_con_winsor2.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_test_cat_winsor2 = pd.get_dummies(X_test_cat_winsor2)\n",
    "\n",
    "drop_na_winsor2 = pd.concat([imputed_X_test_con_winsor2, imputed_X_test_cat_winsor2, X_test_na_winsor2, y_test_winsor2], axis = 1)\n",
    "drop_na_winsor2 = pd.DataFrame(drop_na_winsor2)\n",
    "\n",
    "X_test_final_winsor2 = drop_na_winsor2.loc[:,:'Eigenvector']\n",
    "y_test_final_winsor2 = drop_na_winsor2['ETR']\n",
    "\n",
    "print('Train', X_train_winsor2.shape, y_train_winsor2.shape)\n",
    "print('Test', X_test_winsor2.shape, y_test_winsor2.shape)\n",
    "print('Imputed' , X_train_final_winsor2.shape, y_train_final_winsor2.shape)\n",
    "print('Imputed' , X_test_final_winsor2.shape, y_test_final_winsor2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svr = SVR()\n",
    "svr_random = RandomizedSearchCV(estimator = svr, param_grid = random_grid, n_iter = 10, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random.fit(X_train_final, y_train_final)\n",
    "best_parameters = svr_random.best_estimator_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafdb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [500, 750, 1000, 1250, 1500]\n",
    "gamma = [2, 1.5, 1, 0.5]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svr = SVR()\n",
    "svr_random = RandomizedSearchCV(estimator = svr, param_grid = random_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random.fit(X_train_final, y_train_final)\n",
    "best_parameters = svr_random.best_estimator_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svr_winsor = SVR()\n",
    "svr_random_winsor = GridSearchCV(estimator = svr_winsor, param_grid = random_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random_winsor.fit(X_train_final_winsor, y_train_final_winsor)\n",
    "best_parameters_winsor = svr_random_winsor.best_estimator_\n",
    "print(best_parameters_winsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [0.3, 0.2, 0.1, 0.08, 0.05]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svr_winsor = SVR()\n",
    "svr_random_winsor = GridSearchCV(estimator = svr_winsor, param_grid = random_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random_winsor.fit(X_train_final_winsor, y_train_final_winsor)\n",
    "best_parameters_winsor = svr_random_winsor.best_estimator_\n",
    "print(best_parameters_winsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ab059",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svr_winsor2 = SVR()\n",
    "svr_random_winsor2 = RandomizedSearchCV(estimator = svr_winsor2, param_grid = random_grid, n_iter = 10, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random_winsor2.fit(X_train_final_winsor2, y_train_final_winsor2)\n",
    "best_parameters_winsor2 = svr_random_winsor2.best_estimator_\n",
    "print(best_parameters_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [8, 10, 12]\n",
    "gamma = [0.5, 0.1, 0.05]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svr_winsor2 = SVR()\n",
    "svr_random_winsor2 = GridSearchCV(estimator = svr_winsor2, param_grid = random_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "svr_random_winsor2.fit(X_train_final_winsor2, y_train_final_winsor2)\n",
    "best_parameters_winsor2 = svr_random_winsor2.best_estimator_\n",
    "print(best_parameters_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_for_pred = SVR(C=1500, gamma=0.5)\n",
    "\n",
    "svr_for_pred.fit(X_train_final,y_train_final)\n",
    "\n",
    "y_pred = svr_for_pred.predict(X_test_final)\n",
    "\n",
    "mae = mean_absolute_error(y_test_final, y_pred)\n",
    "mse = mean_squared_error(y_test_final, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "d_nonan = {'With outliers': [mse, rmse, mae]}\n",
    "df_nonan = pd.DataFrame(d_nonan, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred_winsor = SVR(C=100, gamma=0.1)\n",
    "\n",
    "rf_for_pred_winsor.fit(X_train_final_winsor,y_train_final_winsor)\n",
    "\n",
    "y_pred_winsor = rf_for_pred_winsor.predict(X_test_final_winsor)\n",
    "\n",
    "mae_winsor = mean_absolute_error(y_test_final_winsor, y_pred_winsor)\n",
    "mse_winsor = mean_squared_error(y_test_final_winsor, y_pred_winsor)\n",
    "rmse_winsor = np.sqrt(mse_winsor)\n",
    "d_nonan_winsor = {'1% outliers removed': [mse_winsor, rmse_winsor, mae_winsor]}\n",
    "df_nonan_winsor = pd.DataFrame(d_nonan_winsor, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan_winsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ed921",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred_winsor2 = SVR(C=12, gamma=0.1)\n",
    "\n",
    "rf_for_pred_winsor2.fit(X_train_final_winsor2,y_train_final_winsor2)\n",
    "\n",
    "y_pred_winsor2 = rf_for_pred_winsor2.predict(X_test_final_winsor2)\n",
    "\n",
    "mae_winsor2 = mean_absolute_error(y_test_final_winsor2, y_pred_winsor2)\n",
    "mse_winsor2 = mean_squared_error(y_test_final_winsor2, y_pred_winsor2)\n",
    "rmse_winsor2 = np.sqrt(mse_winsor2)\n",
    "d_nonan_winsor2 = {'5% outliers removed': [mse_winsor2, rmse_winsor2, mae_winsor2]}\n",
    "df_nonan_winsor2 = pd.DataFrame(d_nonan_winsor2, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_LR = pd.concat([df_nonan, df_nonan_winsor, df_nonan_winsor2], axis = 1)\n",
    "print(results_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9477325",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_LR.to_excel(\"results_SVM_NA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "y_error = pd.DataFrame(data = [(y_pred_winsor2-y_test_final_winsor2)]).T\n",
    "y_error = pd.concat([X_test_final_winsor2, y_error], axis = 1)\n",
    "\n",
    "cormat = y_error.corr()\n",
    "round(cormat,3)\n",
    "\n",
    "ETR_heatmap = cormat['ETR']\n",
    "ETR_heatmap = pd.DataFrame(ETR_heatmap)\n",
    "ETR_heatmap.rename(columns = {'ETR':'ETR error'}, inplace = True)\n",
    "ETR_heatmap = ETR_heatmap.drop('ETR')\n",
    "\n",
    "figure(figsize=(4, 10), dpi=200)\n",
    "sns.heatmap(ETR_heatmap, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETR_heatmap.sort_values('ETR error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
