{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2cdc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from scipy.stats import mstats\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5715e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Final dataset for real3.xlsx', index_col = 0)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa4ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Country ISO code'] = data['Country ISO code'].astype('category')\n",
    "data['Size'] = data['Size'].astype('category')\n",
    "data['Accounting practice'] = data['Accounting practice'].astype('category')\n",
    "data['NACE Rev. 2'] = data['NACE Rev. 2'].astype('category')\n",
    "\n",
    "X = data[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\"]]\n",
    "y = data[\"ETR\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con = X_train[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_na = X_train[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_train_cat = X_train[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler_con = StandardScaler()\n",
    "scaler_con.fit(X_train_con)\n",
    "scaler_na = StandardScaler()\n",
    "scaler_na.fit(X_train_na)\n",
    "StandardScaler()\n",
    "X_train_con = scaler_con.transform(X_train_con)\n",
    "\n",
    "X_train_na = pd.DataFrame(scaler_na.transform(X_train_na), index = X_train.index)\n",
    "X_train_na.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "iim=IterativeImputer(\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con = pd.DataFrame(iim.fit_transform(X_train_con), index = X_train.index)\n",
    "imputed_X_train_con.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_train_cat = pd.get_dummies(X_train_cat)\n",
    "\n",
    "drop_na = pd.concat([imputed_X_train_con, imputed_X_train_cat, X_train_na, y_train], axis = 1)\n",
    "drop_na = drop_na.dropna()\n",
    "drop_na = pd.DataFrame(drop_na)\n",
    "\n",
    "X_train_final = drop_na.loc[:,:\"Eigenvector\"]\n",
    "y_train_final = drop_na['ETR']\n",
    "\n",
    "X_test_con = X_test[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_na = X_test[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_test_cat = X_test[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con = scaler_con.transform(X_test_con)\n",
    "\n",
    "X_test_na = pd.DataFrame(scaler_na.transform(X_test_na), index = X_test.index)\n",
    "X_test_na.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "imputed_X_test_con = pd.DataFrame(iim.transform(X_test_con), index = X_test.index)\n",
    "imputed_X_test_con.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_test_cat = pd.get_dummies(X_test_cat)\n",
    "\n",
    "drop_na = pd.concat([imputed_X_test_con, imputed_X_test_cat, X_test_na, y_test], axis = 1)\n",
    "drop_na = drop_na.dropna()\n",
    "drop_na = pd.DataFrame(drop_na)\n",
    "\n",
    "X_test_final = drop_na.loc[:,:\"Eigenvector\"]\n",
    "y_test_final = drop_na['ETR']\n",
    "\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)\n",
    "print('Imputed' , X_train_final.shape, y_train_final.shape)\n",
    "print('Imputed_test' , X_test_final.shape, y_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fa155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(dataframe, upper, lower, column_to_winsor):\n",
    "    dataframe = dataframe.sort_values(column_to_winsor, ascending=False, ignore_index = True)\n",
    "    amount = dataframe[column_to_winsor].count()\n",
    "    up = int(amount * (upper/100))\n",
    "    low = int(amount * (lower/100))\n",
    "    data_winsor = dataframe.loc[low:up]\n",
    "    return data_winsor\n",
    "\n",
    "data_winsor = winsorize(data, 99,  1, 'ETR') \n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Operating revenue\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Total assets\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Current liabilities\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Betweenness\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"Long term debt\")\n",
    "data_winsor = winsorize(data_winsor, 99, 1, \"PBT\")\n",
    "\n",
    "X_winsor = data_winsor[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\"]]\n",
    "y_winsor = data_winsor[\"ETR\"]\n",
    "\n",
    "X_train_winsor, X_test_winsor, y_train_winsor, y_test_winsor = train_test_split(X_winsor, y_winsor, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con_winsor = X_train_winsor[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_na_winsor = X_train_winsor[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_train_cat_winsor = X_train_winsor[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler_con_winsor = StandardScaler()\n",
    "scaler_con_winsor.fit(X_train_con_winsor)\n",
    "scaler_na_winsor = StandardScaler()\n",
    "scaler_na_winsor.fit(X_train_na_winsor)\n",
    "StandardScaler()\n",
    "X_train_con_winsor = scaler_con_winsor.transform(X_train_con_winsor)\n",
    "\n",
    "X_train_na_winsor = pd.DataFrame(scaler_na_winsor.transform(X_train_na_winsor), index = X_train_winsor.index)\n",
    "X_train_na_winsor.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "iim=IterativeImputer(\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con_winsor = pd.DataFrame(iim.fit_transform(X_train_con_winsor), index = X_train_winsor.index)\n",
    "imputed_X_train_con_winsor.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_train_cat_winsor = pd.get_dummies(X_train_cat_winsor)\n",
    "\n",
    "drop_na_winsor = pd.concat([imputed_X_train_con_winsor, imputed_X_train_cat_winsor, X_train_na_winsor, y_train_winsor], axis = 1)\n",
    "drop_na_winsor = drop_na_winsor.dropna()\n",
    "drop_na_winsor = pd.DataFrame(drop_na_winsor)\n",
    "\n",
    "X_train_final_winsor = drop_na_winsor.loc[:,:'Eigenvector']\n",
    "y_train_final_winsor = drop_na_winsor['ETR']\n",
    "\n",
    "X_test_con_winsor = X_test_winsor[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_na_winsor = X_test_winsor[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_test_cat_winsor = X_test_winsor[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con_winsor = scaler_con_winsor.transform(X_test_con_winsor)\n",
    "\n",
    "X_test_na_winsor = pd.DataFrame(scaler_na_winsor.transform(X_test_na_winsor), index = X_test_winsor.index)\n",
    "X_test_na_winsor.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "imputed_X_test_con_winsor = pd.DataFrame(iim.transform(X_test_con_winsor), index = X_test_winsor.index)\n",
    "imputed_X_test_con_winsor.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_test_cat_winsor = pd.get_dummies(X_test_cat_winsor)\n",
    "\n",
    "drop_na_winsor = pd.concat([imputed_X_test_con_winsor, imputed_X_test_cat_winsor, X_test_na_winsor, y_test_winsor], axis = 1)\n",
    "drop_na_winsor = pd.DataFrame(drop_na_winsor)\n",
    "\n",
    "X_test_final_winsor = drop_na_winsor.loc[:,:'Eigenvector']\n",
    "y_test_final_winsor = drop_na_winsor['ETR']\n",
    "\n",
    "print('Train', X_train_winsor.shape, y_train_winsor.shape)\n",
    "print('Test', X_test_winsor.shape, y_test_winsor.shape)\n",
    "print('Imputed' , X_train_final_winsor.shape, y_train_final_winsor.shape)\n",
    "print('Imputed' , X_test_final_winsor.shape, y_test_final_winsor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5de6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(dataframe, upper, lower, column_to_winsor):\n",
    "    dataframe = dataframe.sort_values(column_to_winsor, ascending=False, ignore_index = True)\n",
    "    amount = dataframe[column_to_winsor].count()\n",
    "    up = int(amount * (upper/100))\n",
    "    low = int(amount * (lower/100))\n",
    "    data_winsor = dataframe.loc[low:up]\n",
    "    return data_winsor\n",
    "\n",
    "data_winsor2 = winsorize(data, 97.5,  4, 'ETR') \n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Operating revenue\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Total assets\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Current liabilities\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Betweenness\")\n",
    "data_winsor2 = winsorize(data_winsor2, 100,  4, \"Long term debt\")\n",
    "data_winsor2 = winsorize(data_winsor2, 97.5,  2.5, \"PBT\")\n",
    "\n",
    "X_winsor2 = data_winsor2[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\"]]\n",
    "y_winsor2 = data_winsor2[\"ETR\"]\n",
    "\n",
    "X_train_winsor2, X_test_winsor2, y_train_winsor2, y_test_winsor2 = train_test_split(X_winsor2, y_winsor2, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "X_train_con_winsor2 = X_train_winsor2[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_train_na_winsor2 = X_train_winsor2[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_train_cat_winsor2 = X_train_winsor2[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "scaler_con_winsor2 = StandardScaler()\n",
    "scaler_con_winsor2.fit(X_train_con_winsor2)\n",
    "scaler_na_winsor2 = StandardScaler()\n",
    "scaler_na_winsor2.fit(X_train_na_winsor2)\n",
    "StandardScaler()\n",
    "X_train_con_winsor2 = scaler_con_winsor2.transform(X_train_con_winsor2)\n",
    "\n",
    "X_train_na_winsor2 = pd.DataFrame(scaler_na_winsor2.transform(X_train_na_winsor2), index = X_train_winsor2.index)\n",
    "X_train_na_winsor2.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "iim=IterativeImputer(\n",
    "initial_strategy='median',\n",
    "max_iter=10,\n",
    "missing_values= np.nan,\n",
    "random_state=2031996)\n",
    "\n",
    "imputed_X_train_con_winsor2 = pd.DataFrame(iim.fit_transform(X_train_con_winsor2), index = X_train_winsor2.index)\n",
    "imputed_X_train_con_winsor2.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_train_cat_winsor2 = pd.get_dummies(X_train_cat_winsor2)\n",
    "\n",
    "drop_na_winsor2 = pd.concat([imputed_X_train_con_winsor2, imputed_X_train_cat_winsor2, X_train_na_winsor2, y_train_winsor2], axis = 1)\n",
    "drop_na_winsor2 = drop_na_winsor2.dropna()\n",
    "drop_na_winsor2 = pd.DataFrame(drop_na_winsor2)\n",
    "\n",
    "X_train_final_winsor2 = drop_na_winsor2.loc[:,:'Eigenvector']\n",
    "y_train_final_winsor2 = drop_na_winsor2['ETR']\n",
    "\n",
    "X_test_con_winsor2 = X_test_winsor2[[\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]]\n",
    "X_test_na_winsor2 = X_test_winsor2[[\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]]\n",
    "X_test_cat_winsor2 = X_test_winsor2[['NACE Rev. 2', 'Size', 'Accounting practice']]\n",
    "\n",
    "X_test_con_winsor2 = scaler_con_winsor2.transform(X_test_con_winsor2)\n",
    "\n",
    "X_test_na_winsor2 = pd.DataFrame(scaler_na_winsor2.transform(X_test_na_winsor2), index = X_test_winsor2.index)\n",
    "X_test_na_winsor2.columns = [\"Degree\", \"Closeness\", \"Betweenness\", \"Eigenvector\"]\n",
    "\n",
    "imputed_X_test_con_winsor2 = pd.DataFrame(iim.transform(X_test_con_winsor2), index = X_test_winsor2.index)\n",
    "imputed_X_test_con_winsor2.columns = [\"Nr. of Tax Treaties\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\"]\n",
    "imputed_X_test_cat_winsor2 = pd.get_dummies(X_test_cat_winsor2)\n",
    "\n",
    "drop_na_winsor2 = pd.concat([imputed_X_test_con_winsor2, imputed_X_test_cat_winsor2, X_test_na_winsor2, y_test_winsor2], axis = 1)\n",
    "drop_na_winsor2 = pd.DataFrame(drop_na_winsor2)\n",
    "\n",
    "X_test_final_winsor2 = drop_na_winsor2.loc[:,:'Eigenvector']\n",
    "y_test_final_winsor2 = drop_na_winsor2['ETR']\n",
    "\n",
    "print('Train', X_train_winsor2.shape, y_train_winsor2.shape)\n",
    "print('Test', X_test_winsor2.shape, y_test_winsor2.shape)\n",
    "print('Imputed' , X_train_final_winsor2.shape, y_train_final_winsor2.shape)\n",
    "print('Imputed' , X_test_final_winsor2.shape, y_test_final_winsor2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 20, 50]\n",
    "min_samples_leaf = [1, 20, 80]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 200, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train_final, y_train_final)\n",
    "best_parameters = rf_random.best_estimator_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe750c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_winsor = RandomForestRegressor()\n",
    "rf_random_winsor = RandomizedSearchCV(estimator = rf_winsor, param_distributions = random_grid, n_iter = 200, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random_winsor.fit(X_train_final_winsor, y_train_final_winsor)\n",
    "best_parameters_winsor = rf_random_winsor.best_estimator_\n",
    "print(best_parameters_winsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_winsor2 = RandomForestRegressor()\n",
    "rf_random_winsor2 = RandomizedSearchCV(estimator = rf_winsor2, param_distributions = random_grid, n_iter = 200, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random_winsor2.fit(X_train_final_winsor2, y_train_final_winsor2)\n",
    "best_parameters_winsor2 = rf_random_winsor2.best_estimator_\n",
    "print(best_parameters_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [1350, 1550, 1750]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "max_depth = [78, 85, 92]\n",
    "min_samples_split = [35,50,65]\n",
    "min_samples_leaf = [50,80,110]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_winsor2 = RandomForestRegressor()\n",
    "rf_random_winsor2 = GridSearchCV(estimator = rf_winsor2, param_grid = random_grid, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random_winsor2.fit(X_train_final_winsor2, y_train_final_winsor2)\n",
    "best_parameters_winsor2 = rf_random_winsor2.best_estimator_\n",
    "print(best_parameters_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca74a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred = RandomForestRegressor(max_depth=110, max_features='log2', min_samples_leaf=80,\n",
    "                      min_samples_split=50, n_estimators=200)\n",
    "\n",
    "rf_for_pred.fit(X_train_final,y_train_final)\n",
    "\n",
    "y_pred = rf_for_pred.predict(X_test_final)\n",
    "\n",
    "mae = mean_absolute_error(y_test_final, y_pred)\n",
    "mse = mean_squared_error(y_test_final, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "d_nonan = {'With outliers': [mse, rmse, mae]}\n",
    "df_nonan = pd.DataFrame(d_nonan, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred_winsor = RandomForestRegressor(bootstrap=False, max_depth=60, max_features='sqrt',\n",
    "                      n_estimators=650)\n",
    "\n",
    "rf_for_pred_winsor.fit(X_train_final_winsor,y_train_final_winsor)\n",
    "\n",
    "y_pred_winsor = rf_for_pred_winsor.predict(X_test_final_winsor)\n",
    "\n",
    "mae_winsor = mean_absolute_error(y_test_final_winsor, y_pred_winsor)\n",
    "mse_winsor = mean_squared_error(y_test_final_winsor, y_pred_winsor)\n",
    "rmse_winsor = np.sqrt(mse_winsor)\n",
    "d_nonan_winsor = {'1% outliers removed': [mse_winsor, rmse_winsor, mae_winsor]}\n",
    "df_nonan_winsor = pd.DataFrame(d_nonan_winsor, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan_winsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred_winsor = RandomForestRegressor(n_estimators=1100)\n",
    "\n",
    "rf_for_pred_winsor.fit(X_train_final_winsor,y_train_final_winsor)\n",
    "\n",
    "y_pred_winsor = rf_for_pred_winsor.predict(X_test_final_winsor)\n",
    "\n",
    "mae_winsor = mean_absolute_error(y_test_final_winsor, y_pred_winsor)\n",
    "mse_winsor = mean_squared_error(y_test_final_winsor, y_pred_winsor)\n",
    "rmse_winsor = np.sqrt(mse_winsor)\n",
    "d_nonan_winsor = {'1% outliers removed': [mse_winsor, rmse_winsor, mae_winsor]}\n",
    "df_nonan_winsor = pd.DataFrame(d_nonan_winsor, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan_winsor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95426cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred_winsor2 = RandomForestRegressor(bootstrap=False, max_depth=60, max_features='sqrt',\n",
    "                      n_estimators=650)\n",
    "\n",
    "rf_for_pred_winsor2.fit(X_train_final_winsor2,y_train_final_winsor2)\n",
    "\n",
    "y_pred_winsor2 = rf_for_pred_winsor2.predict(X_test_final_winsor2)\n",
    "\n",
    "mae_winsor2 = mean_absolute_error(y_test_final_winsor2, y_pred_winsor2)\n",
    "mse_winsor2 = mean_squared_error(y_test_final_winsor2, y_pred_winsor2)\n",
    "rmse_winsor2 = np.sqrt(mse_winsor2)\n",
    "d_nonan_winsor2 = {'5% outliers removed': [mse_winsor2, rmse_winsor2, mae_winsor2]}\n",
    "df_nonan_winsor2 = pd.DataFrame(d_nonan_winsor2, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_for_pred_winsor2 = RandomForestRegressor(max_depth=85, n_estimators=1550)\n",
    "\n",
    "rf_for_pred_winsor2.fit(X_train_final_winsor2,y_train_final_winsor2)\n",
    "\n",
    "y_pred_winsor2 = rf_for_pred_winsor2.predict(X_test_final_winsor2)\n",
    "\n",
    "mae_winsor2 = mean_absolute_error(y_test_final_winsor2, y_pred_winsor2)\n",
    "mse_winsor2 = mean_squared_error(y_test_final_winsor2, y_pred_winsor2)\n",
    "rmse_winsor2 = np.sqrt(mse_winsor2)\n",
    "d_nonan_winsor2 = {'5% outliers removed': [mse_winsor2, rmse_winsor2, mae_winsor2]}\n",
    "df_nonan_winsor2 = pd.DataFrame(d_nonan_winsor2, index = ['MSE','RMSE','MAE'])\n",
    "print(df_nonan_winsor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad98965",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_LR_RF = pd.concat([df_nonan, df_nonan_winsor, df_nonan_winsor2], axis = 1)\n",
    "print(results_LR_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a06d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_LR_RF.to_excel(\"results_RF_NA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517c975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_list=list(X_train_final.columns)\n",
    "importances = list(rf_for_pred.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Feature: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccc9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_list=list(X_train_final_winsor.columns)\n",
    "importances = list(rf_for_pred_winsor.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Feature: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178dfd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_list=list(X_train_final_winsor2.columns)\n",
    "importances = list(rf_for_pred_winsor2.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Feature: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72acc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(feature_importances)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.to_excel(\"feature_importances_RF.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904db8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "y_error = pd.DataFrame(data = [(y_pred_winsor2-y_test_final_winsor2)]).T\n",
    "y_error = pd.concat([X_test_winsor2, y_error], axis = 1)\n",
    "\n",
    "cormat = y_error.corr()\n",
    "round(cormat,3)\n",
    "\n",
    "ETR_heatmap = cormat['ETR']\n",
    "ETR_heatmap = pd.DataFrame(ETR_heatmap)\n",
    "ETR_heatmap.rename(columns = {'ETR':'ETR error'}, inplace = True)\n",
    "ETR_heatmap = ETR_heatmap.drop('ETR')\n",
    "\n",
    "figure(figsize=(4, 10), dpi=200)\n",
    "sns.heatmap(ETR_heatmap, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e81f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETR_heatmap.sort_values('ETR error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02785d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "X = data[[\"Nr. of Tax Treaties\",\"NACE Rev. 2\",\"Operating revenue\",\"Number of employees\",\n",
    "          \"PBT\",\"Total assets\",\"ROA\",\"No of subsidiaries\",\"Solvency ratio\",\"Long term debt\",\"Debtors\",\n",
    "          \"Current liabilities\", \"Size\",\"Accounting practice\",\"Degree\",\"Closeness\",\"Betweenness\",\"Eigenvector\",\"Hubs\"]]\n",
    "y = data[\"ETR\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state= 2031996, shuffle = True)\n",
    "\n",
    "y_error = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "cormat = y_error.corr()\n",
    "round(cormat,3)\n",
    "\n",
    "figure(figsize=(12, 9), dpi=200)\n",
    "sns.heatmap(cormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527f5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
